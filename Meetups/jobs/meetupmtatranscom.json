{
  "job_name" : "meetupmtatranscom",
  "api_endpoints" : [ ],
  "sql" : "SELECT n.speed, n.travel_time, n.borough, n.link_name, n.link_points,\n       n.latitude, n.longitude, DISTANCE_BETWEEN(CAST(t.latitude as STRING), \n                 CAST(t.latitude as STRING), \n                 m.VehicleLocationLatitude, m.VehicleLocationLongitude) as miles, \n       t.title, t.`description`, t.pubDate, t.latitude, t.longitude,\n       m.VehicleLocationLatitude, m.VehicleLocationLongitude, \n       m.StopPointRef, m.VehicleRef,\n       m.ProgressRate, m.ExpectedDepartureTime, m.StopPoint,\n       m.VisitNumber, m.DataFrameRef, m.StopPointName,\n       m.Bearing, m.OriginAimedDepartureTime, m.OperatorRef,\n       m.DestinationName, m.ExpectedArrivalTime, m.BlockRef,\n       m.LineRef, m.DirectionRef, m.ArrivalProximityText,\n       m.DistanceFromStop, m.EstimatedPassengerCapacity, \n       m.AimedArrivalTime, m.PublishedLineName, \n       m.ProgressStatus, m.DestinationRef, m.EstimatedPassengerCount,\n       m.OriginRef, m.NumberOfStopsAway, m.ts, n.eventTimeStamp, (m.uuid || t.uuid || n.uuid) as allid \nFROM  jsonmta /*+ OPTIONS('scan.startup.mode' = 'earliest-offset') */  m\n      FULL OUTER JOIN jsontranscom /*+ OPTIONS('scan.startup.mode' = 'earliest-offset') */  t\n       ON (t.latitude >= CAST(m.VehicleLocationLatitude as float) - 0.3) \n       AND (t.longitude >= CAST(m.VehicleLocationLongitude as float) - 0.3) \n       AND (t.latitude <= CAST(m.VehicleLocationLatitude as float) + 0.3) \n       AND (t.longitude <= CAST(m.VehicleLocationLongitude as float) + 0.3)   \n     FULL OUTER JOIN nytrafficspeed /*+ OPTIONS('scan.startup.mode' = 'earliest-offset') */  n\n     ON (n.latitude >= CAST(m.VehicleLocationLatitude as float) - 0.3) \n     AND (n.longitude >= CAST(m.VehicleLocationLongitude as float) - 0.3) \n     AND (n.latitude <= CAST(m.VehicleLocationLatitude as float) + 0.3) \n     AND (n.longitude <= CAST(m.VehicleLocationLongitude as float) + 0.3) \nWHERE m.VehicleRef is not null  \nAND   t.title is not null",
  "mv_config" : {
    "name" : "meetupmtatranscom",
    "retention" : 300,
    "min_row_retention_count" : 0,
    "recreate" : false,
    "key_column_name" : null,
    "api_key" : null,
    "ignore_nulls" : false,
    "require_restart" : false,
    "batch_size" : 0,
    "enabled" : false
  },
  "runtime_config" : {
    "execution_mode" : "SESSION",
    "parallelism" : 1,
    "sample_interval" : 1000,
    "sample_count" : 1000,
    "window_size" : 1000,
    "start_with_savepoint" : true,
    "log_config" : {
      "type" : "LOG4J_PROPERTIES",
      "content" : "\nrootLogger.level = INFO\nrootLogger.appenderRef.file.ref = MainAppender\n#Uncomment this if you want to _only_ change Flink's logging\n#logger.flink.name = org.apache.flink\n#logger.flink.level = INFO\n\n# The following lines keep the log level of common libraries/connectors on\n# log level INFO. The root logger does not override this. You have to manually\n# change the log levels here.\nlogger.akka.name = akka\nlogger.akka.level = INFO\nlogger.kafka.name= org.apache.kafka\nlogger.kafka.level = INFO\nlogger.hadoop.name = org.apache.hadoop\nlogger.hadoop.level = INFO\nlogger.zookeeper.name = org.apache.zookeeper\nlogger.zookeeper.level = INFO\n\n# Log all infos in the given file\nappender.main.name = MainAppender\nappender.main.type = File\nappender.main.append = false\nappender.main.fileName = /var/log/ssb\nappender.main.layout.type = PatternLayout\nappender.main.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n\n\n# Suppress the irrelevant (wrong) warnings from the Netty channel handler\nlogger.netty.name = org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline\nlogger.netty.level = OFF\n"
    }
  }
}